{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0NzlndUXNRa",
        "outputId": "e34c0ba4-fe3a-4ebc-f25c-580faef45898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 186 kB/s \n",
            "\u001b[?25hCollecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 142 kB/s \n",
            "\u001b[?25hCollecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 29.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=206188a258a246a4f5eb36151a937927adcc5e37a893e42335db54329ba75c1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для произвольного предложения или текста решите следующие задачи:\n",
        "Токенизация.\n",
        "Частеречная разметка.\n",
        "Лемматизация.\n",
        "Выделение (распознавание) именованных сущностей.\n",
        "Разбор предложения.\n",
        "Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
        "Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
        "Способ 2. На основе моделей word2vec или Glove или fastText.\n",
        "Сравните качество полученных моделей.\n"
      ],
      "metadata": {
        "id": "bqUUwfjWZkyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='Старая тетка Варвара Ивановна решила, что Наташу, ставшую невестой, нужно строго охранять. От чего понадобилось охранять молодую девушку -- тетка не знала хорошенько, но в разговоре ее появилось множество врачебных советов и практических замечаний, В этом поддержали родители жениха, старики Стабесовы, Марья Митрофановна и Николай Африканович, снимавшие у Томилиных в лесу дачу.'"
      ],
      "metadata": {
        "id": "rbH9QCLLZl1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка текста\n",
        "\n",
        "Токенизация\n"
      ],
      "metadata": {
        "id": "bmkQ0H4CZ4HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcZfXEG8yIoo",
        "outputId": "2014e53a-1c82-4f3d-9394-8e42565aa018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize"
      ],
      "metadata": {
        "id": "0je0JOy2xsrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_tok_text = list(tokenize(text))\n",
        "n_tok_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpu5r7LHx1qj",
        "outputId": "5e6b7bbe-03aa-45ff-d173-3d20e30530c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 6, 'Старая'),\n",
              " Substring(7, 12, 'тетка'),\n",
              " Substring(13, 20, 'Варвара'),\n",
              " Substring(21, 29, 'Ивановна'),\n",
              " Substring(30, 36, 'решила'),\n",
              " Substring(36, 37, ','),\n",
              " Substring(38, 41, 'что'),\n",
              " Substring(42, 48, 'Наташу'),\n",
              " Substring(48, 49, ','),\n",
              " Substring(50, 57, 'ставшую'),\n",
              " Substring(58, 66, 'невестой'),\n",
              " Substring(66, 67, ','),\n",
              " Substring(68, 73, 'нужно'),\n",
              " Substring(74, 80, 'строго'),\n",
              " Substring(81, 89, 'охранять'),\n",
              " Substring(89, 90, '.'),\n",
              " Substring(91, 93, 'От'),\n",
              " Substring(94, 98, 'чего'),\n",
              " Substring(99, 111, 'понадобилось'),\n",
              " Substring(112, 120, 'охранять'),\n",
              " Substring(121, 128, 'молодую'),\n",
              " Substring(129, 136, 'девушку'),\n",
              " Substring(137, 139, '--'),\n",
              " Substring(140, 145, 'тетка'),\n",
              " Substring(146, 148, 'не'),\n",
              " Substring(149, 154, 'знала'),\n",
              " Substring(155, 165, 'хорошенько'),\n",
              " Substring(165, 166, ','),\n",
              " Substring(167, 169, 'но'),\n",
              " Substring(170, 171, 'в'),\n",
              " Substring(172, 181, 'разговоре'),\n",
              " Substring(182, 184, 'ее'),\n",
              " Substring(185, 194, 'появилось'),\n",
              " Substring(195, 204, 'множество'),\n",
              " Substring(205, 214, 'врачебных'),\n",
              " Substring(215, 222, 'советов'),\n",
              " Substring(223, 224, 'и'),\n",
              " Substring(225, 237, 'практических'),\n",
              " Substring(238, 247, 'замечаний'),\n",
              " Substring(247, 248, ','),\n",
              " Substring(249, 250, 'В'),\n",
              " Substring(251, 255, 'этом'),\n",
              " Substring(256, 266, 'поддержали'),\n",
              " Substring(267, 275, 'родители'),\n",
              " Substring(276, 282, 'жениха'),\n",
              " Substring(282, 283, ','),\n",
              " Substring(284, 291, 'старики'),\n",
              " Substring(292, 301, 'Стабесовы'),\n",
              " Substring(301, 302, ','),\n",
              " Substring(303, 308, 'Марья'),\n",
              " Substring(309, 321, 'Митрофановна'),\n",
              " Substring(322, 323, 'и'),\n",
              " Substring(324, 331, 'Николай'),\n",
              " Substring(332, 343, 'Африканович'),\n",
              " Substring(343, 344, ','),\n",
              " Substring(345, 354, 'снимавшие'),\n",
              " Substring(355, 356, 'у'),\n",
              " Substring(357, 366, 'Томилиных'),\n",
              " Substring(367, 368, 'в'),\n",
              " Substring(369, 373, 'лесу'),\n",
              " Substring(374, 378, 'дачу'),\n",
              " Substring(378, 379, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_tok_text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T5XRTsGyUJb",
        "outputId": "cc4e42e6-5447-4955-a747-15237c7411f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Старая',\n",
              " 'тетка',\n",
              " 'Варвара',\n",
              " 'Ивановна',\n",
              " 'решила',\n",
              " ',',\n",
              " 'что',\n",
              " 'Наташу',\n",
              " ',',\n",
              " 'ставшую',\n",
              " 'невестой',\n",
              " ',',\n",
              " 'нужно',\n",
              " 'строго',\n",
              " 'охранять',\n",
              " '.',\n",
              " 'От',\n",
              " 'чего',\n",
              " 'понадобилось',\n",
              " 'охранять',\n",
              " 'молодую',\n",
              " 'девушку',\n",
              " '--',\n",
              " 'тетка',\n",
              " 'не',\n",
              " 'знала',\n",
              " 'хорошенько',\n",
              " ',',\n",
              " 'но',\n",
              " 'в',\n",
              " 'разговоре',\n",
              " 'ее',\n",
              " 'появилось',\n",
              " 'множество',\n",
              " 'врачебных',\n",
              " 'советов',\n",
              " 'и',\n",
              " 'практических',\n",
              " 'замечаний',\n",
              " ',',\n",
              " 'В',\n",
              " 'этом',\n",
              " 'поддержали',\n",
              " 'родители',\n",
              " 'жениха',\n",
              " ',',\n",
              " 'старики',\n",
              " 'Стабесовы',\n",
              " ',',\n",
              " 'Марья',\n",
              " 'Митрофановна',\n",
              " 'и',\n",
              " 'Николай',\n",
              " 'Африканович',\n",
              " ',',\n",
              " 'снимавшие',\n",
              " 'у',\n",
              " 'Томилиных',\n",
              " 'в',\n",
              " 'лесу',\n",
              " 'дачу',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_text = list(sentenize(text))\n",
        "n_sen_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpPA04_8yW5-",
        "outputId": "21ddd5cd-6235-4c8c-a644-93a842e44158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0,\n",
              "           90,\n",
              "           'Старая тетка Варвара Ивановна решила, что Наташу, ставшую невестой, нужно строго охранять.'),\n",
              " Substring(91,\n",
              "           379,\n",
              "           'От чего понадобилось охранять молодую девушку -- тетка не знала хорошенько, но в разговоре ее появилось множество врачебных советов и практических замечаний, В этом поддержали родители жениха, старики Стабесовы, Марья Митрофановна и Николай Африканович, снимавшие у Томилиных в лесу дачу.')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_fIyahcyZoN",
        "outputId": "0723853f-ebd8-47bc-d66c-d7decd1c16c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Старая тетка Варвара Ивановна решила, что Наташу, ставшую невестой, нужно строго охранять.',\n",
              "  'От чего понадобилось охранять молодую девушку -- тетка не знала хорошенько, но в разговоре ее появилось множество врачебных советов и практических замечаний, В этом поддержали родители жениха, старики Стабесовы, Марья Митрофановна и Николай Африканович, снимавшие у Томилиных в лесу дачу.'],\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот вариант токенизации нужен для последующей обработки\n",
        "def n_sentenize(text):\n",
        "    n_sen_chunk = []\n",
        "    for sent in sentenize(text):\n",
        "        tokens = [_.text for _ in tokenize(sent.text)]\n",
        "        n_sen_chunk.append(tokens)\n",
        "    return n_sen_chunk"
      ],
      "metadata": {
        "id": "quUrFtrMydlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk = n_sentenize(text)\n",
        "n_sen_chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUqkH9c5yfvi",
        "outputId": "df1cc768-3ec6-4f9d-a275-0ddc067b4f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Старая',\n",
              "  'тетка',\n",
              "  'Варвара',\n",
              "  'Ивановна',\n",
              "  'решила',\n",
              "  ',',\n",
              "  'что',\n",
              "  'Наташу',\n",
              "  ',',\n",
              "  'ставшую',\n",
              "  'невестой',\n",
              "  ',',\n",
              "  'нужно',\n",
              "  'строго',\n",
              "  'охранять',\n",
              "  '.'],\n",
              " ['От',\n",
              "  'чего',\n",
              "  'понадобилось',\n",
              "  'охранять',\n",
              "  'молодую',\n",
              "  'девушку',\n",
              "  '--',\n",
              "  'тетка',\n",
              "  'не',\n",
              "  'знала',\n",
              "  'хорошенько',\n",
              "  ',',\n",
              "  'но',\n",
              "  'в',\n",
              "  'разговоре',\n",
              "  'ее',\n",
              "  'появилось',\n",
              "  'множество',\n",
              "  'врачебных',\n",
              "  'советов',\n",
              "  'и',\n",
              "  'практических',\n",
              "  'замечаний',\n",
              "  ',',\n",
              "  'В',\n",
              "  'этом',\n",
              "  'поддержали',\n",
              "  'родители',\n",
              "  'жениха',\n",
              "  ',',\n",
              "  'старики',\n",
              "  'Стабесовы',\n",
              "  ',',\n",
              "  'Марья',\n",
              "  'Митрофановна',\n",
              "  'и',\n",
              "  'Николай',\n",
              "  'Африканович',\n",
              "  ',',\n",
              "  'снимавшие',\n",
              "  'у',\n",
              "  'Томилиных',\n",
              "  'в',\n",
              "  'лесу',\n",
              "  'дачу',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9302f1"
      },
      "source": [
        "# 3.1 Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5380144e"
      },
      "source": [
        "Способ 1. На основе CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73f30bc0",
        "outputId": "7dd33831-7baa-4d9b-9401-0c1c2b959a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "660dacce"
      },
      "outputs": [],
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f85bb68",
        "outputId": "fef48bb2-83ed-4fa7-959e-3d160a541747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Emotion\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-829a3dde-fe8b-45a4-8508-6eb90a4a2446\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-829a3dde-fe8b-45a4-8508-6eb90a4a2446')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-829a3dde-fe8b-45a4-8508-6eb90a4a2446 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-829a3dde-fe8b-45a4-8508-6eb90a4a2446');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df=pd.read_csv(\"Emotion_final.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7366940",
        "outputId": "bfcc9fbc-6a59-42ce-f575-335a7b54e27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text    value\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f339b8e0-fca1-4f9d-b8bf-e97c1e9a5a16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f339b8e0-fca1-4f9d-b8bf-e97c1e9a5a16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f339b8e0-fca1-4f9d-b8bf-e97c1e9a5a16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f339b8e0-fca1-4f9d-b8bf-e97c1e9a5a16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Только держать колонки \"Text\" и \"Emotion\".\n",
        "df_new = pd.DataFrame(df,columns=['Text','Emotion'])\n",
        "df_new.columns = ['text','value']\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8a651639",
        "outputId": "e602f7eb-43c9-417b-f53f-8be18791f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21459, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e03d54bb",
        "outputId": "2c154b7e-c679-4725-faeb-c6c33a9f7a4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy',\n",
              " 'ive been feeling a little burdened lately wasnt sure why that was',\n",
              " 'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny',\n",
              " 'i feel as confused about life as a teenager or as jaded as a year old man',\n",
              " 'i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
              " 'i feel romantic too']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Сформируем общий словарь\n",
        "vocab_list = df_new['text'].tolist()\n",
        "vocab_list[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72d8a671",
        "outputId": "238aba25-bc2f-43c9-8469-061aecb440c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 18910\n"
          ]
        }
      ],
      "source": [
        "vocabVect = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1),  #ngram_range=(1, 1) is the default\n",
        "    dtype='double'\n",
        ")\n",
        "vocabVect.fit(vocab_list)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e9d88d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9792dab-dd22-42bc-cb27-c9eabadf1593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feel=6175\n",
            "humiliated=8063\n",
            "feeling=6179\n",
            "hopeless=7940\n",
            "damned=4034\n",
            "hopeful=7937\n",
            "just=9101\n",
            "cares=2460\n",
            "awake=1188\n"
          ]
        }
      ],
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6784b7d"
      },
      "outputs": [],
      "source": [
        "test_features = vocabVect.transform(vocab_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db93f4cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c07f30-eb3d-42d7-e443-1f472870fc4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<21459x18910 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 174657 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e310156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9aa80e1-fbfc-4066-8208-a6059dc2175d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "test_features.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83e7ff9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7304fa2f-325e-48f5-a300-5ad7704fc747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18910"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6090c451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cf1b95-1148-4901-8d90-a577d62c16cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Непустые значения нулевой строки\n",
        "[i for i in test_features.todense()[0].getA1() if i>0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85fd857e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecfce9d-e125-4e9d-d981-ef11ea7609e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstain',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'absurd',\n",
              " 'absurdity',\n",
              " 'absurdly',\n",
              " 'abt',\n",
              " 'abu',\n",
              " 'abundance',\n",
              " 'abundantly',\n",
              " 'abus',\n",
              " 'abuse',\n",
              " 'abused',\n",
              " 'abuses',\n",
              " 'abusing',\n",
              " 'abusive',\n",
              " 'abyss',\n",
              " 'ac',\n",
              " 'academia',\n",
              " 'academic']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vocabVect.get_feature_names()[100:120]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "241dcd8b"
      },
      "source": [
        "Разделим выборку на обучающую и тестовую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e10e0eec"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new['text'], df_new['value'], test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbeaf053"
      },
      "outputs": [],
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc22136f"
      },
      "source": [
        "Используем классификатор \"LogisticRegression\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26662231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555957ae-f4f0-48ae-d9f9-765f51ca3a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "anger \t 0.8617614269788183\n",
            "fear \t 0.8179453836150845\n",
            "happy \t 0.9302873292510598\n",
            "love \t 0.7651991614255765\n",
            "sadness \t 0.927159209157128\n",
            "surprise \t 0.652\n"
          ]
        }
      ],
      "source": [
        "sentiment(CountVectorizer(), LogisticRegression(C=3.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df00bab4"
      },
      "source": [
        "Способ 2. На основе моделей word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b76070e9"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edd4b437"
      },
      "outputs": [],
      "source": [
        "# Подготовим корпус\n",
        "corpus = []\n",
        "stop_words = stopwords.words('english')\n",
        "tok = WordPunctTokenizer()\n",
        "for line in df_new['text'].values:\n",
        "    line1 = line.strip().lower()\n",
        "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
        "    text_tok = tok.tokenize(line1)\n",
        "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
        "    corpus.append(text_tok1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb573f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8ebd54-a09e-40d8-dcb5-d0805e94295e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['didnt', 'feel', 'humiliated'],\n",
              " ['go',\n",
              "  'feeling',\n",
              "  'hopeless',\n",
              "  'damned',\n",
              "  'hopeful',\n",
              "  'around',\n",
              "  'someone',\n",
              "  'cares',\n",
              "  'awake'],\n",
              " ['im', 'grabbing', 'minute', 'post', 'feel', 'greedy', 'wrong'],\n",
              " ['ever', 'feeling', 'nostalgic', 'fireplace', 'know', 'still', 'property'],\n",
              " ['feeling', 'grouchy']]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "corpus[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a023bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c777a97f-fec5-4f66-9df6-0d7785c1e0ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['didnt', 'feel', 'humiliated'],\n",
              " ['go',\n",
              "  'feeling',\n",
              "  'hopeless',\n",
              "  'damned',\n",
              "  'hopeful',\n",
              "  'around',\n",
              "  'someone',\n",
              "  'cares',\n",
              "  'awake'],\n",
              " ['im', 'grabbing', 'minute', 'post', 'feel', 'greedy', 'wrong'],\n",
              " ['ever', 'feeling', 'nostalgic', 'fireplace', 'know', 'still', 'property'],\n",
              " ['feeling', 'grouchy']]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "corpus[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "574edb1a"
      },
      "outputs": [],
      "source": [
        "assert df_new.shape[0]==len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52a90d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20940c51-0f0e-432c-d02a-e577bb4d347c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.56 s, sys: 175 ms, total: 2.73 s\n",
            "Wall time: 1.96 s\n"
          ]
        }
      ],
      "source": [
        "%time model_imdb = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af279279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b15ce5d-f983-4fab-f465-d1af072d69d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('meet', 0.999535322189331), ('learn', 0.9994907379150391), ('team', 0.9994804859161377), ('says', 0.9994664788246155), ('students', 0.9994622468948364), ('open', 0.9994584918022156), ('smile', 0.9994581341743469), ('wife', 0.9994560480117798), ('call', 0.9994525909423828), ('certain', 0.999447226524353)]\n"
          ]
        }
      ],
      "source": [
        "# Проверим, что модель обучилась\n",
        "print(model_imdb.wv.most_similar(positive=['adventure'], topn=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7cea9df"
      },
      "outputs": [],
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    '''\n",
        "    Для текста усредним вектора входящих в него слов\n",
        "    '''\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean(\n",
        "            [self.model[w] for w in words if w in self.model] \n",
        "            or [np.zeros(self.size)], axis=0)\n",
        "            for words in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5752ebb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c691b3a7-8675-4da1-a322-84b7ed5e6f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "anger \t 0.0\n",
            "fear \t 0.0\n",
            "happy \t 0.898728214790391\n",
            "love \t 0.0\n",
            "sadness \t 0.14984391259105098\n",
            "surprise \t 0.0\n"
          ]
        }
      ],
      "source": [
        "sentiment(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=3.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a29fa113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f172e7f3-7f98-4b2f-be68-fd603efe9010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "anger \t 0.0\n",
            "fear \t 0.0\n",
            "happy \t 0.8794159208666981\n",
            "love \t 0.0\n",
            "sadness \t 0.16805411030176898\n",
            "surprise \t 0.0\n"
          ]
        }
      ],
      "source": [
        "sentiment(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1d4ad85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70078979-b611-43ac-83f2-4098e3f189f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "anger \t 0.1705685618729097\n",
            "fear \t 0.12483745123537061\n",
            "happy \t 0.46302402260951486\n",
            "love \t 0.025157232704402517\n",
            "sadness \t 0.2757544224765869\n",
            "surprise \t 0.012\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "sentiment(EmbeddingVectorizer(model_imdb.wv), KNeighborsClassifier(n_neighbors=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6681fec"
      },
      "outputs": [],
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f6fef77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4cf5aa-dc81-4962-92e7-6166395146f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "anger \t 0.0\n",
            "fear \t 0.0\n",
            "happy \t 0.8794159208666981\n",
            "love \t 0.0\n",
            "sadness \t 0.16805411030176898\n",
            "surprise \t 0.0\n"
          ]
        }
      ],
      "source": [
        "sentiment(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_d_Mv-x-T3H-",
    "outputId": "788eb3d0-6762-43cd-addf-824ee3f09002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in ./opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: navec>=0.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: pymorphy2 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: yargy>=0.14.0 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: razdel>=0.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: intervaltree>=3 in ./opt/anaconda3/lib/python3.9/site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from navec>=0.9.0->natasha) (1.22.3)\n",
      "Requirement already satisfied: docopt>=0.6 in ./opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in ./opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PzcoQIIAT3FG"
   },
   "outputs": [],
   "source": [
    "from razdel import tokenize, sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Проснулась сельская местность, проснулись цветы и растения перед домами и за домами. Первым делом жена фермера открыла клетки с курами, утками и гусями и выпустила их кормиться; утки крякали, гуси крякали; они отдыхали всю ночь, и их кряканье было громким и полным энергии; собаки и кошки ходили вокруг своих хозяев, казалось, с желанием подразнить и страстью к бешенству; старые коровы с сонным выражением лица были выведены хозяевами на обочину дороги и привязаны к кустам, свободно обгладывая нежную траву под ногами, изредка выпуская \"Кухня начала суетиться со звоном кастрюль и сковородок и ароматом душистых кастрюль и сковородок, источающих запах дня.\n",
    "'''\n",
    "text2 = '''荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住，只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾；但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打彩的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声；但热闹是它们的， 我什么也没有。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFKrpDYvT3CW",
    "outputId": "06b0c364-dc1d-4cf6-903f-100fac5013df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 10, 'Проснулась'),\n",
       " Substring(11, 19, 'сельская'),\n",
       " Substring(20, 29, 'местность'),\n",
       " Substring(29, 30, ','),\n",
       " Substring(31, 41, 'проснулись'),\n",
       " Substring(42, 47, 'цветы'),\n",
       " Substring(48, 49, 'и'),\n",
       " Substring(50, 58, 'растения'),\n",
       " Substring(59, 64, 'перед'),\n",
       " Substring(65, 71, 'домами'),\n",
       " Substring(72, 73, 'и'),\n",
       " Substring(74, 76, 'за'),\n",
       " Substring(77, 83, 'домами'),\n",
       " Substring(83, 84, '.'),\n",
       " Substring(85, 91, 'Первым'),\n",
       " Substring(92, 97, 'делом'),\n",
       " Substring(98, 102, 'жена'),\n",
       " Substring(103, 110, 'фермера'),\n",
       " Substring(111, 118, 'открыла'),\n",
       " Substring(119, 125, 'клетки'),\n",
       " Substring(126, 127, 'с'),\n",
       " Substring(128, 134, 'курами'),\n",
       " Substring(134, 135, ','),\n",
       " Substring(136, 142, 'утками'),\n",
       " Substring(143, 144, 'и'),\n",
       " Substring(145, 151, 'гусями'),\n",
       " Substring(152, 153, 'и'),\n",
       " Substring(154, 163, 'выпустила'),\n",
       " Substring(164, 166, 'их'),\n",
       " Substring(167, 176, 'кормиться'),\n",
       " Substring(176, 177, ';'),\n",
       " Substring(178, 182, 'утки'),\n",
       " Substring(183, 190, 'крякали'),\n",
       " Substring(190, 191, ','),\n",
       " Substring(192, 196, 'гуси'),\n",
       " Substring(197, 204, 'крякали'),\n",
       " Substring(204, 205, ';'),\n",
       " Substring(206, 209, 'они'),\n",
       " Substring(210, 218, 'отдыхали'),\n",
       " Substring(219, 222, 'всю'),\n",
       " Substring(223, 227, 'ночь'),\n",
       " Substring(227, 228, ','),\n",
       " Substring(229, 230, 'и'),\n",
       " Substring(231, 233, 'их'),\n",
       " Substring(234, 242, 'кряканье'),\n",
       " Substring(243, 247, 'было'),\n",
       " Substring(248, 255, 'громким'),\n",
       " Substring(256, 257, 'и'),\n",
       " Substring(258, 264, 'полным'),\n",
       " Substring(265, 272, 'энергии'),\n",
       " Substring(272, 273, ';'),\n",
       " Substring(274, 280, 'собаки'),\n",
       " Substring(281, 282, 'и'),\n",
       " Substring(283, 288, 'кошки'),\n",
       " Substring(289, 295, 'ходили'),\n",
       " Substring(296, 302, 'вокруг'),\n",
       " Substring(303, 308, 'своих'),\n",
       " Substring(309, 315, 'хозяев'),\n",
       " Substring(315, 316, ','),\n",
       " Substring(317, 325, 'казалось'),\n",
       " Substring(325, 326, ','),\n",
       " Substring(327, 328, 'с'),\n",
       " Substring(329, 337, 'желанием'),\n",
       " Substring(338, 348, 'подразнить'),\n",
       " Substring(349, 350, 'и'),\n",
       " Substring(351, 359, 'страстью'),\n",
       " Substring(360, 361, 'к'),\n",
       " Substring(362, 371, 'бешенству'),\n",
       " Substring(371, 372, ';'),\n",
       " Substring(373, 379, 'старые'),\n",
       " Substring(380, 386, 'коровы'),\n",
       " Substring(387, 388, 'с'),\n",
       " Substring(389, 395, 'сонным'),\n",
       " Substring(396, 406, 'выражением'),\n",
       " Substring(407, 411, 'лица'),\n",
       " Substring(412, 416, 'были'),\n",
       " Substring(417, 425, 'выведены'),\n",
       " Substring(426, 435, 'хозяевами'),\n",
       " Substring(436, 438, 'на'),\n",
       " Substring(439, 446, 'обочину'),\n",
       " Substring(447, 453, 'дороги'),\n",
       " Substring(454, 455, 'и'),\n",
       " Substring(456, 465, 'привязаны'),\n",
       " Substring(466, 467, 'к'),\n",
       " Substring(468, 474, 'кустам'),\n",
       " Substring(474, 475, ','),\n",
       " Substring(476, 484, 'свободно'),\n",
       " Substring(485, 495, 'обгладывая'),\n",
       " Substring(496, 502, 'нежную'),\n",
       " Substring(503, 508, 'траву'),\n",
       " Substring(509, 512, 'под'),\n",
       " Substring(513, 519, 'ногами'),\n",
       " Substring(519, 520, ','),\n",
       " Substring(521, 528, 'изредка'),\n",
       " Substring(529, 537, 'выпуская'),\n",
       " Substring(538, 539, '\"'),\n",
       " Substring(539, 544, 'Кухня'),\n",
       " Substring(545, 551, 'начала'),\n",
       " Substring(552, 561, 'суетиться'),\n",
       " Substring(562, 564, 'со'),\n",
       " Substring(565, 571, 'звоном'),\n",
       " Substring(572, 580, 'кастрюль'),\n",
       " Substring(581, 582, 'и'),\n",
       " Substring(583, 593, 'сковородок'),\n",
       " Substring(594, 595, 'и'),\n",
       " Substring(596, 604, 'ароматом'),\n",
       " Substring(605, 613, 'душистых'),\n",
       " Substring(614, 622, 'кастрюль'),\n",
       " Substring(623, 624, 'и'),\n",
       " Substring(625, 635, 'сковородок'),\n",
       " Substring(635, 636, ','),\n",
       " Substring(637, 647, 'источающих'),\n",
       " Substring(648, 653, 'запах'),\n",
       " Substring(654, 657, 'дня'),\n",
       " Substring(657, 658, '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tok_text = list(tokenize(text))\n",
    "n_tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fau-OnLjUfW4"
   },
   "outputs": [],
   "source": [
    "text = '''Проснулась сельская местность, проснулись цветы и растения перед домами и за домами. Первым делом жена фермера открыла клетки с курами, утками и гусями и выпустила их кормиться; утки крякали, гуси крякали; они отдыхали всю ночь, и их кряканье было громким и полным энергии; собаки и кошки ходили вокруг своих хозяев, казалось, с желанием подразнить и страстью к бешенству; старые коровы с сонным выражением лица были выведены хозяевами на обочину дороги и привязаны к кустам, свободно обгладывая нежную траву под ногами, изредка выпуская \"Кухня начала суетиться со звоном кастрюль и сковородок и ароматом душистых кастрюль и сковородок, источающих запах дня.\n",
    "'''\n",
    "text2 = '''荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住，只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾；但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打彩的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声；但热闹是它们的， 我什么也没有。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkYXGk3aUiQl",
    "outputId": "46df4cba-80b2-4f1d-926d-d4fad4c4109d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Проснулась',\n",
       " 'сельская',\n",
       " 'местность',\n",
       " ',',\n",
       " 'проснулись',\n",
       " 'цветы',\n",
       " 'и',\n",
       " 'растения',\n",
       " 'перед',\n",
       " 'домами',\n",
       " 'и',\n",
       " 'за',\n",
       " 'домами',\n",
       " '.',\n",
       " 'Первым',\n",
       " 'делом',\n",
       " 'жена',\n",
       " 'фермера',\n",
       " 'открыла',\n",
       " 'клетки',\n",
       " 'с',\n",
       " 'курами',\n",
       " ',',\n",
       " 'утками',\n",
       " 'и',\n",
       " 'гусями',\n",
       " 'и',\n",
       " 'выпустила',\n",
       " 'их',\n",
       " 'кормиться',\n",
       " ';',\n",
       " 'утки',\n",
       " 'крякали',\n",
       " ',',\n",
       " 'гуси',\n",
       " 'крякали',\n",
       " ';',\n",
       " 'они',\n",
       " 'отдыхали',\n",
       " 'всю',\n",
       " 'ночь',\n",
       " ',',\n",
       " 'и',\n",
       " 'их',\n",
       " 'кряканье',\n",
       " 'было',\n",
       " 'громким',\n",
       " 'и',\n",
       " 'полным',\n",
       " 'энергии',\n",
       " ';',\n",
       " 'собаки',\n",
       " 'и',\n",
       " 'кошки',\n",
       " 'ходили',\n",
       " 'вокруг',\n",
       " 'своих',\n",
       " 'хозяев',\n",
       " ',',\n",
       " 'казалось',\n",
       " ',',\n",
       " 'с',\n",
       " 'желанием',\n",
       " 'подразнить',\n",
       " 'и',\n",
       " 'страстью',\n",
       " 'к',\n",
       " 'бешенству',\n",
       " ';',\n",
       " 'старые',\n",
       " 'коровы',\n",
       " 'с',\n",
       " 'сонным',\n",
       " 'выражением',\n",
       " 'лица',\n",
       " 'были',\n",
       " 'выведены',\n",
       " 'хозяевами',\n",
       " 'на',\n",
       " 'обочину',\n",
       " 'дороги',\n",
       " 'и',\n",
       " 'привязаны',\n",
       " 'к',\n",
       " 'кустам',\n",
       " ',',\n",
       " 'свободно',\n",
       " 'обгладывая',\n",
       " 'нежную',\n",
       " 'траву',\n",
       " 'под',\n",
       " 'ногами',\n",
       " ',',\n",
       " 'изредка',\n",
       " 'выпуская',\n",
       " '\"',\n",
       " 'Кухня',\n",
       " 'начала',\n",
       " 'суетиться',\n",
       " 'со',\n",
       " 'звоном',\n",
       " 'кастрюль',\n",
       " 'и',\n",
       " 'сковородок',\n",
       " 'и',\n",
       " 'ароматом',\n",
       " 'душистых',\n",
       " 'кастрюль',\n",
       " 'и',\n",
       " 'сковородок',\n",
       " ',',\n",
       " 'источающих',\n",
       " 'запах',\n",
       " 'дня',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_tok_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kz5Y4ewwUiA1",
    "outputId": "f2505c08-1278-41c2-b9b4-4e9cd5dc930c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0,\n",
       "           84,\n",
       "           'Проснулась сельская местность, проснулись цветы и растения перед домами и за домами.'),\n",
       " Substring(85,\n",
       "           658,\n",
       "           'Первым делом жена фермера открыла клетки с курами, утками и гусями и выпустила их кормиться; утки крякали, гуси крякали; они отдыхали всю ночь, и их кряканье было громким и полным энергии; собаки и кошки ходили вокруг своих хозяев, казалось, с желанием подразнить и страстью к бешенству; старые коровы с сонным выражением лица были выведены хозяевами на обочину дороги и привязаны к кустам, свободно обгладывая нежную траву под ногами, изредка выпуская \"Кухня начала суетиться со звоном кастрюль и сковородок и ароматом душистых кастрюль и сковородок, источающих запах дня.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_text = list(sentenize(text))\n",
    "n_sen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h39isZRrUpGW",
    "outputId": "9b3bb332-cdcf-47ff-a196-66ffc555ec2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Проснулась сельская местность, проснулись цветы и растения перед домами и за домами.',\n",
       "  'Первым делом жена фермера открыла клетки с курами, утками и гусями и выпустила их кормиться; утки крякали, гуси крякали; они отдыхали всю ночь, и их кряканье было громким и полным энергии; собаки и кошки ходили вокруг своих хозяев, казалось, с желанием подразнить и страстью к бешенству; старые коровы с сонным выражением лица были выведены хозяевами на обочину дороги и привязаны к кустам, свободно обгладывая нежную траву под ногами, изредка выпуская \"Кухня начала суетиться со звоном кастрюль и сковородок и ароматом душистых кастрюль и сковородок, источающих запах дня.'],\n",
       " 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YHaOHG08UpD1"
   },
   "outputs": [],
   "source": [
    "# Этот вариант токенизации нужен для последующей обработки\n",
    "def n_sentenize(text):\n",
    "    n_sen_chunk = []\n",
    "    for sent in sentenize(text):\n",
    "        tokens = [_.text for _ in tokenize(sent.text)]\n",
    "        n_sen_chunk.append(tokens)\n",
    "    return n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoBBMAPkUpA-",
    "outputId": "4075893a-5704-4e1d-bc9d-a72d4549c7f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Проснулась',\n",
       "  'сельская',\n",
       "  'местность',\n",
       "  ',',\n",
       "  'проснулись',\n",
       "  'цветы',\n",
       "  'и',\n",
       "  'растения',\n",
       "  'перед',\n",
       "  'домами',\n",
       "  'и',\n",
       "  'за',\n",
       "  'домами',\n",
       "  '.'],\n",
       " ['Первым',\n",
       "  'делом',\n",
       "  'жена',\n",
       "  'фермера',\n",
       "  'открыла',\n",
       "  'клетки',\n",
       "  'с',\n",
       "  'курами',\n",
       "  ',',\n",
       "  'утками',\n",
       "  'и',\n",
       "  'гусями',\n",
       "  'и',\n",
       "  'выпустила',\n",
       "  'их',\n",
       "  'кормиться',\n",
       "  ';',\n",
       "  'утки',\n",
       "  'крякали',\n",
       "  ',',\n",
       "  'гуси',\n",
       "  'крякали',\n",
       "  ';',\n",
       "  'они',\n",
       "  'отдыхали',\n",
       "  'всю',\n",
       "  'ночь',\n",
       "  ',',\n",
       "  'и',\n",
       "  'их',\n",
       "  'кряканье',\n",
       "  'было',\n",
       "  'громким',\n",
       "  'и',\n",
       "  'полным',\n",
       "  'энергии',\n",
       "  ';',\n",
       "  'собаки',\n",
       "  'и',\n",
       "  'кошки',\n",
       "  'ходили',\n",
       "  'вокруг',\n",
       "  'своих',\n",
       "  'хозяев',\n",
       "  ',',\n",
       "  'казалось',\n",
       "  ',',\n",
       "  'с',\n",
       "  'желанием',\n",
       "  'подразнить',\n",
       "  'и',\n",
       "  'страстью',\n",
       "  'к',\n",
       "  'бешенству',\n",
       "  ';',\n",
       "  'старые',\n",
       "  'коровы',\n",
       "  'с',\n",
       "  'сонным',\n",
       "  'выражением',\n",
       "  'лица',\n",
       "  'были',\n",
       "  'выведены',\n",
       "  'хозяевами',\n",
       "  'на',\n",
       "  'обочину',\n",
       "  'дороги',\n",
       "  'и',\n",
       "  'привязаны',\n",
       "  'к',\n",
       "  'кустам',\n",
       "  ',',\n",
       "  'свободно',\n",
       "  'обгладывая',\n",
       "  'нежную',\n",
       "  'траву',\n",
       "  'под',\n",
       "  'ногами',\n",
       "  ',',\n",
       "  'изредка',\n",
       "  'выпуская',\n",
       "  '\"',\n",
       "  'Кухня',\n",
       "  'начала',\n",
       "  'суетиться',\n",
       "  'со',\n",
       "  'звоном',\n",
       "  'кастрюль',\n",
       "  'и',\n",
       "  'сковородок',\n",
       "  'и',\n",
       "  'ароматом',\n",
       "  'душистых',\n",
       "  'кастрюль',\n",
       "  'и',\n",
       "  'сковородок',\n",
       "  ',',\n",
       "  'источающих',\n",
       "  'запах',\n",
       "  'дня',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk = n_sentenize(text)\n",
    "n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYmypvIOUzKM",
    "outputId": "06479367-5251-4c39-f7e7-946d9e28e419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住，只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾；但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打彩的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声；但热闹是它们的，',\n",
       "  '我什么也没有。']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk_2 = n_sentenize(text2)\n",
    "n_sen_chunk_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtioU-lxVLF5"
   },
   "source": [
    "**Частеречная разметка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h_3260opVMnW"
   },
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "g3FUpCk4VM3t"
   },
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
    "#navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j7r2cELZVYyN"
   },
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
    "#n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dhVW2VbqVYtV"
   },
   "outputs": [],
   "source": [
    "#morph_res = n_morph.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_6RlFkjVYqm"
   },
   "outputs": [],
   "source": [
    "def print_pos(markup):\n",
    "    for token in markup.tokens:\n",
    "        print('{} - {}'.format(token.text, token.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdSaULk_Vhj9"
   },
   "outputs": [],
   "source": [
    "#n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
    "#[print_pos(x) for x in n_text_markup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0XQ2ndlVhdF"
   },
   "outputs": [],
   "source": [
    "#n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
    "#[print_pos(x) for x in n_text2_markup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "g_zsWRI6Vr18"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s9WC21aqVru8"
   },
   "outputs": [],
   "source": [
    "def n_lemmatize(text):\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    segmenter = Segmenter()\n",
    "    morph_vocab = MorphVocab()\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrL0mmW_VrKW",
    "outputId": "7b5fe100-efbf-46f4-ad0f-5cbbe63affb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Проснулась': 'проснуться',\n",
       " 'сельская': 'сельский',\n",
       " 'местность': 'местность',\n",
       " ',': ',',\n",
       " 'проснулись': 'проснуться',\n",
       " 'цветы': 'цветок',\n",
       " 'и': 'и',\n",
       " 'растения': 'растение',\n",
       " 'перед': 'перед',\n",
       " 'домами': 'дом',\n",
       " 'за': 'за',\n",
       " '.': '.',\n",
       " 'Первым': 'первый',\n",
       " 'делом': 'дело',\n",
       " 'жена': 'жена',\n",
       " 'фермера': 'фермер',\n",
       " 'открыла': 'открыть',\n",
       " 'клетки': 'клетка',\n",
       " 'с': 'с',\n",
       " 'курами': 'кура',\n",
       " 'утками': 'уток',\n",
       " 'гусями': 'гусь',\n",
       " 'выпустила': 'выпустить',\n",
       " 'их': 'они',\n",
       " 'кормиться': 'кормиться',\n",
       " ';': ';',\n",
       " 'утки': 'утка',\n",
       " 'крякали': 'крякать',\n",
       " 'гуси': 'гусь',\n",
       " 'они': 'они',\n",
       " 'отдыхали': 'отдыхать',\n",
       " 'всю': 'весь',\n",
       " 'ночь': 'ночь',\n",
       " 'кряканье': 'кряканье',\n",
       " 'было': 'быть',\n",
       " 'громким': 'громкий',\n",
       " 'полным': 'полный',\n",
       " 'энергии': 'энергия',\n",
       " 'собаки': 'собака',\n",
       " 'кошки': 'кошка',\n",
       " 'ходили': 'ходить',\n",
       " 'вокруг': 'вокруг',\n",
       " 'своих': 'свой',\n",
       " 'хозяев': 'хозяин',\n",
       " 'казалось': 'казаться',\n",
       " 'желанием': 'желание',\n",
       " 'подразнить': 'подразнить',\n",
       " 'страстью': 'страсть',\n",
       " 'к': 'к',\n",
       " 'бешенству': 'бешенство',\n",
       " 'старые': 'старый',\n",
       " 'коровы': 'корова',\n",
       " 'сонным': 'сонный',\n",
       " 'выражением': 'выражение',\n",
       " 'лица': 'лицо',\n",
       " 'были': 'быть',\n",
       " 'выведены': 'вывести',\n",
       " 'хозяевами': 'хозяин',\n",
       " 'на': 'на',\n",
       " 'обочину': 'обочина',\n",
       " 'дороги': 'дорога',\n",
       " 'привязаны': 'привязать',\n",
       " 'кустам': 'куст',\n",
       " 'свободно': 'свободно',\n",
       " 'обгладывая': 'обгладывать',\n",
       " 'нежную': 'нежный',\n",
       " 'траву': 'трава',\n",
       " 'под': 'под',\n",
       " 'ногами': 'нога',\n",
       " 'изредка': 'изредка',\n",
       " 'выпуская': 'выпускать',\n",
       " '\"': '\"',\n",
       " 'Кухня': 'кухня',\n",
       " 'начала': 'начать',\n",
       " 'суетиться': 'суетиться',\n",
       " 'со': 'с',\n",
       " 'звоном': 'звон',\n",
       " 'кастрюль': 'кастрюля',\n",
       " 'сковородок': 'сковородка',\n",
       " 'ароматом': 'аромат',\n",
       " 'душистых': 'душистый',\n",
       " 'источающих': 'источать',\n",
       " 'запах': 'запах',\n",
       " 'дня': 'день'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc = n_lemmatize(text)\n",
    "{_.text: _.lemma for _ in n_doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tic-V6QXV1Sg",
    "outputId": "c655ab78-3de0-446c-c41c-bf9490d8ada8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住，只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾；但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打彩的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声；但热闹是它们的，': '荷塘的四面，远远近近，高高低低都是树，而杨柳最多。这些树将一片荷塘重重围住，只在小路一旁，漏着几段空隙，像是特为月光留下的。树色一例是阴阴的，乍看像一团烟雾；但杨柳的丰姿，便在烟雾里也辨得出。树梢上隐隐约约的是一带远山，只有些大意罢了。树缝里也漏着一两点路灯光，没精打彩的，是渴睡人的眼。这时候最热闹的，要数树上的蝉声与水里的蛙声；但热闹是它们的，',\n",
       " '我什么也没有。': '我什么也没有。'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc2 = n_lemmatize(text2)\n",
    "{_.text: _.lemma for _ in n_doc2.tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "011oA5TZV-FG"
   },
   "source": [
    "**Выделение (распознавание) именованных сущностей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vvmt4Y0dV1P1"
   },
   "outputs": [],
   "source": [
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7Ge8w4meV1NN"
   },
   "outputs": [],
   "source": [
    "#ner = NER.load('slovnet_ner_news_v1.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "UmweQQC7WHUV"
   },
   "outputs": [],
   "source": [
    "#ner_res = ner.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CfaWVrMpWHQ-"
   },
   "outputs": [],
   "source": [
    "#markup_ner = ner(text2)\n",
    "#markup_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3hnhE2skWHL1"
   },
   "outputs": [],
   "source": [
    "#show_markup(markup_ner.text, markup_ner.spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c-CyYvsWWl0"
   },
   "source": [
    "**Разбор предложения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "B-ucWJ8mWVHf"
   },
   "outputs": [],
   "source": [
    "from natasha import NewsSyntaxParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9wfWSbD4WVD9"
   },
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNPG_1n_WVBU",
    "outputId": "aa33f496-6862-4274-d415-a857c05c6555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Проснулась \n",
      "        ┌► сельская   amod\n",
      "        └─ местность  \n",
      "        ┌► ,          punct\n",
      "      ┌─└─ проснулись \n",
      "    ┌─└──► цветы      nsubj\n",
      "    │   ┌► и          cc\n",
      "  ┌─└──►└─ растения   conj\n",
      "  │     ┌► перед      case\n",
      "┌─└────►└─ домами     nmod\n",
      "│     ┌──► и          cc\n",
      "│     │ ┌► за         case\n",
      "└────►└─└─ домами     conj\n",
      "           .          \n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrOSl44SWi4q",
    "outputId": "37e4d13c-7e57-49b1-d783-9b62d5e93ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ┌► Первым     amod\n",
      "              ┌────────────────────────────────────────────►└─ делом      obl\n",
      "              │                                           ┌►┌─ жена       nsubj\n",
      "              │                                           │ └► фермера    nmod\n",
      "  ┌───┌─────┌─│                                       ┌───└─┌─ открыла    \n",
      "  │   │     │ │                                       │     └► клетки     obj\n",
      "  │   │     │ │                                       │     ┌► с          case\n",
      "┌─│   │     │ │             ┌──────────────────────►┌─│ ┌─┌─└─ курами     nmod\n",
      "│ │   │     │ │             │                       │ │ │ │ ┌► ,          punct\n",
      "│ │   │     │ │             │                       │ │ │ └►└─ утками     conj\n",
      "│ │   │     │ │             │                       │ │ │   ┌► и          cc\n",
      "│ │   │     │ │             │                       │ │ └──►└─ гусями     conj\n",
      "│ │   │     │ │             │                       │ │     ┌► и          cc\n",
      "│ │   │     │ │             │                       │ └►┌─┌─└─ выпустила  conj\n",
      "│ │   │     │ │             │                       │   │ │ ┌► их         obj\n",
      "│ │   │     │ │             │                       │   │ └►└─ кормиться  xcomp\n",
      "│ │   │     │ │             │                       │ ┌►│      ;          punct\n",
      "│ │ ┌►│     │ │             │                       │ │ │      утки       conj\n",
      "│ │ │ │     │ │             │                       │ │ └────► крякали    parataxis\n",
      "│ │ │ │     │ │             │                       │ │     ┌► ,          punct\n",
      "│ │ │ │   ┌►│ │             │                       │ │     │  гуси       amod\n",
      "│ │ │ │   │ │ │             │                       └►│     └─ крякали    conj\n",
      "│ │ │ │   │ │ │   ┌────────►│                         │        ;          punct\n",
      "│ │ │ │   │ │ │   │         │                         │     ┌► они        nsubj\n",
      "│ │ │ │   │ │ │   │         │         ┌──────────────►└─────└─ отдыхали   conj\n",
      "│ │ │ │   │ │ │   │         │         │                     ┌► всю        det\n",
      "│ │ │ │   │ │ │ ┌►│         │         │                     └─ ночь       obl\n",
      "│ │ │ │   │ │ │ │ │     ┌──►│         │                        ,          punct\n",
      "│ │ │ │   │ │ │ │ │     │ ┌►│         │                        и          cc\n",
      "│ │ │ │   │ │ │ │ │     │ │ │         │                     ┌► их         det\n",
      "│ │ │ │   │ │ │ │ │   ┌►│ │ │         │                     └─ кряканье   conj\n",
      "│ │ │ │   │ │ │ │ │   │ │ │ │         │     ┌────────────────► было       aux:pass\n",
      "│ │ │ │   │ │ │ │ │   │ │ │ │         │     │           ┌►┌─── громким    amod\n",
      "│ │ │ │   │ │ │ │ │   │ │ │ │         │     │           │ │ ┌► и          cc\n",
      "│ │ │ │   │ │ │ │ │   │ │ │ │         │     │           │ └►└─ полным     conj\n",
      "│ │ │ │ ┌─│ │ │ │ │ ┌►│ │ │ │       ┌─│     │           └───── энергии    nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │   ┌──►│ │     │                  ;          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ ┌►│   │ │     │             ┌─── собаки     nsubj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │             │ ┌► и          cc\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │             └►└─ кошки      conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │     ┌─────────── ходили     \n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │     │       ┌──► вокруг     case\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │     │       │ ┌► своих      det\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │     │ ┌──►│       └─└─ хозяев     obl\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   ┌►│ │   │            ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ ┌►│         ┌─ казалось   parataxis\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │         └► ,          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │         ┌► с          case\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ ┌────►┌─└─ желанием   obl\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │     └──► подразнить nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │       ┌► и          cc\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │ ┌►│ │ │ │ │ │     ┌─└─ страстью   conj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │ │ │ │ │ │ │ │     │ ┌► к          case\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │ │ │ │ │ │ │ │     └►└─ бешенству  nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │ │ │ │ │ │ │ │ ┌──────► ;          punct\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │ │ │ │ │ │ │ │ │     ┌► старые     amod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │ └─│ │   │ │ │ │ │ │ │ └►│ │ ┌───└─ коровы     nsubj\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │ │   │ │ │ ┌──► с          case\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │ │   │ │ │ │ ┌► сонным     amod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │ │   │ │ └►└─└─ выражением nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │ │   │ │   └──► лица       nmod\n",
      "│ │ │ │ │ │ │ │ │ │ │ │ │ │   │ │   │ │ │ │ │ │ │   │ │     ┌► были       aux:pass\n",
      "│ │ │ │ │ │ │ └─│ │ │ │ │ │   │ │ ┌─│ └─│ │ └─└─└───└─└───┌─└─ выведены   \n",
      "│ │ │ │ │ │ │   │ │ │ │ │ │   │ │ │ │   │ │               └──► хозяевами  obl\n",
      "│ │ │ │ │ │ │   │ │ │ │ │ │   │ │ │ │   │ │                 ┌► на         case\n",
      "│ │ │ │ │ │ └──►│ │ │ │ │ │   │ │ │ │   │ │               ┌─└─ обочину    obl\n",
      "│ │ │ │ │ │     │ │ │ │ │ │   │ │ │ │   │ │               └──► дороги     nmod\n",
      "│ │ │ │ │ │     │ │ │ │ │ │   │ │ │ │   │ │                 ┌► и          cc\n",
      "│ │ │ └►│ │     │ │ │ │ │ │   │ │ │ │   │ │               ┌─└─ привязаны  conj\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │ │   │ │               │ ┌► к          case\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │ │   │ │               └►└─ кустам     obl\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │ │   │ │               ┌──► ,          punct\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │ │   │ │               │ ┌► свободно   advmod\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │ └──►│ │     ┌─────┌─┌─└─└─ обгладывая acl\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │     │ │   ┌► нежную     amod\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │     │ └──►└─ траву      obj\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │     │     ┌► под        case\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │   ┌►│     └─ ногами     obl\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │   │ └──────► ,          punct\n",
      "│ │ │   │ │     │ │ │ │ │ │   │ │ │     │ │     │   │       ┌► изредка    advmod\n",
      "│ └►│   │ │     │ └─│ │ └─└───│ └─│     │ └─────│ ┌─│       └─ выпуская   advcl\n",
      "│   │   │ │     │   │ │       │   │     │       │ │ │     ┌──► \"          punct\n",
      "│   │   │ └─────│   │ │       │   │     │       │ │ │     │ ┌► Кухня      nsubj\n",
      "│   └───│       │   │ └───────└───│     │       │ │ │     └─└─ начала     \n",
      "│       │       └───│             │     │       │ │ └───┌─└──► суетиться  xcomp\n",
      "│       │           │             │     │       │ │     │   ┌► со         case\n",
      "│       │           │             │     │       │ │     └►┌─└─ звоном     obl\n",
      "│       │           │             │     └───────│ │ ┌───┌─└──► кастрюль   nmod\n",
      "│       │           │             │             │ │ │   │   ┌► и          cc\n",
      "│       │           │             │             │ │ │ ┌─└──►└─ сковородок conj\n",
      "│       │           │             │             │ │ │ │     ┌► и          cc\n",
      "│       │           └─────────────│             │ │ └►│   ┌─└─ ароматом   conj\n",
      "│       │                         │             │ │   └──►│    душистых   amod\n",
      "│       │                         │             │ │       └──► кастрюль   nmod\n",
      "│       │                         │             │ │         ┌► и          cc\n",
      "└──────►│                         │             │ │         └─ сковородок conj\n",
      "        │                         │             └►│            ,          punct\n",
      "        └────────────────────────►│               │            источающих acl\n",
      "                                  │               └────────►┌─ запах      obj\n",
      "                                  │                         └► дня        nmod\n",
      "                                  └──────────────────────────► .          punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[1].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMRI3303Wi2Q",
    "outputId": "fef53d30-3a28-41fa-fdd8-5360096bbbe5",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xw7taYRRWiz1",
    "outputId": "3d69c59d-57b0-472b-b422-d22056fafe4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOg53nuaWr5-"
   },
   "source": [
    "**Векторизация текста на основе модели \"мешка слов\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXUx7JZcWixe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIYSroT9WxGk"
   },
   "outputs": [],
   "source": [
    "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP0VqSCnWxEA"
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Md67aO7IXHee",
    "outputId": "74ddfcb8-4527-4fbd-d462-1f22901f9f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 33448\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(data)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNr5pePAXHbp",
    "outputId": "0850b3b0-d4c7-4f8b-ec33-c27a1dcbc6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmendel=22213\n",
      "unix=31462\n",
      "amherst=5287\n",
      "edu=12444\n",
      "nathaniel=21624\n",
      "mendell=20477\n",
      "subject=29220\n",
      "re=25369\n",
      "bike=6898\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkmv0hEvXPMl"
   },
   "source": [
    "**Использование класса CountVectorizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngR7NdL1XHSV",
    "outputId": "33753389-d23b-4f2a-b176-b492495c8599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 335176 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(data)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sa5rzPOXURk",
    "outputId": "d24eafb1-c2e2-4a3e-e790-a7241d7d14db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7K4wtyEXUNW",
    "outputId": "81c03055-4992-4a2e-801e-34f02cce792b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33448"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(test_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhZU8PuSXUKl",
    "outputId": "3504fd95-1a7c-4c33-e274-8162bdcdbd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in test_features.todense()[0].getA1() if i>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKzkubzmXZkE",
    "outputId": "53ed0666-dc93-4c72-d081-3a6803a3f67b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '0000000004',\n",
       " '0000000005',\n",
       " '0000000667',\n",
       " '0000001200',\n",
       " '0001',\n",
       " '00014',\n",
       " '0002']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabVect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIpzk9_IXeN-"
   },
   "source": [
    "**Решение задачи анализа тональности текста на основе модели \"мешка слов\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHe3P0nxXZhd"
   },
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6QzdJGhXZe_",
    "outputId": "f7f43674-aa77-4f45-e4b4-b91f9633f11b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.937813339432037\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.9453742497059174\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.6655358653541747\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhZ2SMzkXpo1"
   },
   "source": [
    "**Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_R-BzOOXk94"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8tFwYgIXk7P"
   },
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2et9Zn_Xk4s",
    "outputId": "5aec6c32-7784-4efd-b7ca-4091a3566867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.9290322580645162\n",
      "1 \t 0.9675090252707581\n",
      "2 \t 0.9026845637583892\n",
      "3 \t 0.9245901639344263\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WxV1QZcX53R"
   },
   "source": [
    "**Работа с векторными представлениями слов с использованием word2vec**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaAapr50X38G"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1nzYKXjX30d",
    "outputId": "f3593a86-4a66-471b-8ef9-1e5f21922227"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
       " <http.client.HTTPMessage at 0x7f60cd9e4910>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzhdRxseX3x-"
   },
   "outputs": [],
   "source": [
    "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XaQ5hEFYLAC"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg7VROkMYK9W"
   },
   "outputs": [],
   "source": [
    "words = ['холод_S', 'мороз_S', 'береза_S', 'сосна_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Fvm4Y7tYK6_",
    "outputId": "3dc5090a-7a80-493b-c836-a3cc7b4c474f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "СЛОВО - холод_S\n",
      "5 ближайших соседей слова:\n",
      "стужа_S => 0.7676383852958679\n",
      "сырость_S => 0.6338975429534912\n",
      "жара_S => 0.6089427471160889\n",
      "мороз_S => 0.5890367031097412\n",
      "озноб_S => 0.5776054859161377\n",
      "\n",
      "СЛОВО - мороз_S\n",
      "5 ближайших соседей слова:\n",
      "стужа_S => 0.6425479650497437\n",
      "морозец_S => 0.5947279930114746\n",
      "холод_S => 0.5890367031097412\n",
      "жара_S => 0.5522176623344421\n",
      "снегопад_S => 0.5083199143409729\n",
      "\n",
      "СЛОВО - береза_S\n",
      "5 ближайших соседей слова:\n",
      "сосна_S => 0.7943247556686401\n",
      "тополь_S => 0.7562226057052612\n",
      "дуб_S => 0.7440178394317627\n",
      "дерево_S => 0.7373415231704712\n",
      "клен_S => 0.7105200290679932\n",
      "\n",
      "СЛОВО - сосна_S\n",
      "5 ближайших соседей слова:\n",
      "береза_S => 0.7943247556686401\n",
      "дерево_S => 0.7581434845924377\n",
      "лиственница_S => 0.747814953327179\n",
      "дуб_S => 0.7412480711936951\n",
      "ель_S => 0.7363824248313904\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in model:\n",
    "        print('\\nСЛОВО - {}'.format(word))\n",
    "        print('5 ближайших соседей слова:')\n",
    "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
    "            print('{} => {}'.format(word, sim))\n",
    "    else:\n",
    "        print('Слово \"{}\" не найдено в модели'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tWn4tNBYXPe"
   },
   "source": [
    "**Находим близость между словами и строим аналогии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBqx9UEYTVF",
    "outputId": "257504a2-5346-4467-9339-8bad9a96b5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('сырость_S', 0.5040211081504822), ('стылость_S', 0.46336129307746887), ('голод_S', 0.4604816436767578), ('зной_S', 0.45904627442359924), ('скука_S', 0.4489358067512512), ('жара_S', 0.44645121693611145), ('усталость_S', 0.4218570291996002), ('озноб_S', 0.41469818353652954), ('духота_S', 0.4099087715148926), ('неуют_S', 0.40298789739608765)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['холод_S', 'стужа_S'], negative=['мороз_S']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvrZqeBJYey0"
   },
   "source": [
    "**Обучим word2vec на наборе данных \"fetch_20newsgroups\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cAnC3hqYTvV",
    "outputId": "9fd4bfaf-a473-4291-c633-6ab96d90336e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2S8IVk3YTKt"
   },
   "outputs": [],
   "source": [
    "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzdpmL03YmDE"
   },
   "outputs": [],
   "source": [
    "# Подготовим корпус\n",
    "corpus = []\n",
    "stop_words = stopwords.words('english')\n",
    "tok = WordPunctTokenizer()\n",
    "for line in newsgroups['data']:\n",
    "    line1 = line.strip().lower()\n",
    "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
    "    text_tok = tok.tokenize(line1)\n",
    "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
    "    corpus.append(text_tok1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41k7UBpvYmAx",
    "outputId": "8d7a026a-540a-4d31-b8c0-209eb6143739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nrmendel',\n",
       "  'unix',\n",
       "  'amherst',\n",
       "  'edu',\n",
       "  'nathaniel',\n",
       "  'mendell',\n",
       "  'subject',\n",
       "  'bike',\n",
       "  'advice',\n",
       "  'organization',\n",
       "  'amherst',\n",
       "  'college',\n",
       "  'x',\n",
       "  'newsreader',\n",
       "  'tin',\n",
       "  'version',\n",
       "  'pl',\n",
       "  'lines',\n",
       "  'ummm',\n",
       "  'bikes',\n",
       "  'kx',\n",
       "  'suggest',\n",
       "  'look',\n",
       "  'zx',\n",
       "  'since',\n",
       "  'horsepower',\n",
       "  'whereas',\n",
       "  'might',\n",
       "  'bit',\n",
       "  'much',\n",
       "  'sincerely',\n",
       "  'nathaniel',\n",
       "  'zx',\n",
       "  'dod',\n",
       "  'ama'],\n",
       " ['grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'subject',\n",
       "  'krillean',\n",
       "  'photography',\n",
       "  'reply',\n",
       "  'grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'organization',\n",
       "  'rosemount',\n",
       "  'inc',\n",
       "  'lines',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'aquarius',\n",
       "  'stgprao',\n",
       "  'st',\n",
       "  'unocal',\n",
       "  'com',\n",
       "  'richard',\n",
       "  'ottolini',\n",
       "  'writes',\n",
       "  'living',\n",
       "  'things',\n",
       "  'maintain',\n",
       "  'small',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'enhance',\n",
       "  'certain',\n",
       "  'chemical',\n",
       "  'reactions',\n",
       "  'promote',\n",
       "  'communication',\n",
       "  'states',\n",
       "  'cell',\n",
       "  'communicate',\n",
       "  'cells',\n",
       "  'nervous',\n",
       "  'system',\n",
       "  'specialized',\n",
       "  'example',\n",
       "  'perhaps',\n",
       "  'uses',\n",
       "  'true',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'change',\n",
       "  'location',\n",
       "  'time',\n",
       "  'large',\n",
       "  'organism',\n",
       "  'also',\n",
       "  'true',\n",
       "  'special',\n",
       "  'photographic',\n",
       "  'techniques',\n",
       "  'applying',\n",
       "  'external',\n",
       "  'fields',\n",
       "  'kirillian',\n",
       "  'photography',\n",
       "  'interact',\n",
       "  'fields',\n",
       "  'resistances',\n",
       "  'caused',\n",
       "  'fields',\n",
       "  'make',\n",
       "  'interesting',\n",
       "  'pictures',\n",
       "  'really',\n",
       "  'kirlian',\n",
       "  'photography',\n",
       "  'taking',\n",
       "  'pictures',\n",
       "  'corona',\n",
       "  'discharge',\n",
       "  'objects',\n",
       "  'animate',\n",
       "  'inanimate',\n",
       "  'fields',\n",
       "  'applied',\n",
       "  'objects',\n",
       "  'millions',\n",
       "  'times',\n",
       "  'larger',\n",
       "  'biologically',\n",
       "  'created',\n",
       "  'fields',\n",
       "  'want',\n",
       "  'record',\n",
       "  'biologically',\n",
       "  'created',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'got',\n",
       "  'use',\n",
       "  'low',\n",
       "  'noise',\n",
       "  'high',\n",
       "  'gain',\n",
       "  'sensors',\n",
       "  'typical',\n",
       "  'eegs',\n",
       "  'ekgs',\n",
       "  'kirlian',\n",
       "  'photography',\n",
       "  'phun',\n",
       "  'physics',\n",
       "  'type',\n",
       "  'stuff',\n",
       "  'right',\n",
       "  'soaking',\n",
       "  'chunks',\n",
       "  'extra',\n",
       "  'fine',\n",
       "  'steel',\n",
       "  'wool',\n",
       "  'liquid',\n",
       "  'oxygen',\n",
       "  'hitting',\n",
       "  'hammer',\n",
       "  'like',\n",
       "  'kirlean',\n",
       "  'setup',\n",
       "  'fun',\n",
       "  'possibly',\n",
       "  'dangerous',\n",
       "  'perhaps',\n",
       "  'pictures',\n",
       "  'diagonistic',\n",
       "  'disease',\n",
       "  'problems',\n",
       "  'organisms',\n",
       "  'better',\n",
       "  'understood',\n",
       "  'perhaps',\n",
       "  'probably',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'yow',\n",
       "  'vote',\n",
       "  'rosemount',\n",
       "  'inc',\n",
       "  'well',\n",
       "  'tapered',\n",
       "  'half',\n",
       "  'cocked',\n",
       "  'ill',\n",
       "  'conceived',\n",
       "  'grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'tax',\n",
       "  'deferred'],\n",
       " ['liny',\n",
       "  'sun',\n",
       "  'scri',\n",
       "  'fsu',\n",
       "  'edu',\n",
       "  'nemo',\n",
       "  'subject',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'myopia',\n",
       "  'reply',\n",
       "  'lin',\n",
       "  'ray',\n",
       "  'met',\n",
       "  'fsu',\n",
       "  'edu',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'organization',\n",
       "  'scri',\n",
       "  'florida',\n",
       "  'state',\n",
       "  'university',\n",
       "  'lines',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'work',\n",
       "  'first',\n",
       "  'heard',\n",
       "  'newsgroup',\n",
       "  'several',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'got',\n",
       "  'hold',\n",
       "  'book',\n",
       "  'improve',\n",
       "  'sight',\n",
       "  'simple',\n",
       "  'daily',\n",
       "  'drills',\n",
       "  'relaxation',\n",
       "  'margaret',\n",
       "  'corbett',\n",
       "  'authorized',\n",
       "  'instructor',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'published',\n",
       "  'talks',\n",
       "  'vision',\n",
       "  'improvement',\n",
       "  'relaxation',\n",
       "  'exercise',\n",
       "  'study',\n",
       "  'whether',\n",
       "  'method',\n",
       "  'actually',\n",
       "  'works',\n",
       "  'works',\n",
       "  'actually',\n",
       "  'shortening',\n",
       "  'previously',\n",
       "  'elongated',\n",
       "  'eyeball',\n",
       "  'increasing',\n",
       "  'lens',\n",
       "  'ability',\n",
       "  'flatten',\n",
       "  'order',\n",
       "  'compensate',\n",
       "  'long',\n",
       "  'eyeball',\n",
       "  'since',\n",
       "  'myopia',\n",
       "  'result',\n",
       "  'eyeball',\n",
       "  'elongation',\n",
       "  'seems',\n",
       "  'logical',\n",
       "  'approach',\n",
       "  'correction',\n",
       "  'find',\n",
       "  'way',\n",
       "  'reverse',\n",
       "  'process',\n",
       "  'e',\n",
       "  'shorten',\n",
       "  'somehow',\n",
       "  'preferably',\n",
       "  'non',\n",
       "  'surgically',\n",
       "  'recent',\n",
       "  'studies',\n",
       "  'find',\n",
       "  'know',\n",
       "  'rk',\n",
       "  'works',\n",
       "  'changing',\n",
       "  'curvature',\n",
       "  'cornea',\n",
       "  'compensate',\n",
       "  'shape',\n",
       "  'eyeball',\n",
       "  'way',\n",
       "  'train',\n",
       "  'muscles',\n",
       "  'shorten',\n",
       "  'eyeball',\n",
       "  'back',\n",
       "  'correct',\n",
       "  'length',\n",
       "  'would',\n",
       "  'even',\n",
       "  'better',\n",
       "  'bates',\n",
       "  'idea',\n",
       "  'right',\n",
       "  'thanks',\n",
       "  'information'],\n",
       " ['mcovingt',\n",
       "  'aisun',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'michael',\n",
       "  'covington',\n",
       "  'subject',\n",
       "  'buy',\n",
       "  'parts',\n",
       "  'time',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'aisun',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'organization',\n",
       "  'ai',\n",
       "  'programs',\n",
       "  'university',\n",
       "  'georgia',\n",
       "  'athens',\n",
       "  'lines',\n",
       "  'pricing',\n",
       "  'parts',\n",
       "  'reminds',\n",
       "  'something',\n",
       "  'chemist',\n",
       "  'said',\n",
       "  'gram',\n",
       "  'dye',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'comes',\n",
       "  'liter',\n",
       "  'jar',\n",
       "  'also',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'want',\n",
       "  'whole',\n",
       "  'barrel',\n",
       "  'also',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'e',\n",
       "  'charge',\n",
       "  'almost',\n",
       "  'exclusively',\n",
       "  'packaging',\n",
       "  'delivering',\n",
       "  'chemical',\n",
       "  'particular',\n",
       "  'case',\n",
       "  'byproduct',\n",
       "  'cost',\n",
       "  'almost',\n",
       "  'nothing',\n",
       "  'intrinsically',\n",
       "  'michael',\n",
       "  'covington',\n",
       "  'associate',\n",
       "  'research',\n",
       "  'scientist',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'programs',\n",
       "  'mcovingt',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'university',\n",
       "  'georgia',\n",
       "  'phone',\n",
       "  'athens',\n",
       "  'georgia',\n",
       "  'u',\n",
       "  'amateur',\n",
       "  'radio',\n",
       "  'n',\n",
       "  'tmi'],\n",
       " ['tammy',\n",
       "  'vandenboom',\n",
       "  'launchpad',\n",
       "  'unc',\n",
       "  'edu',\n",
       "  'tammy',\n",
       "  'vandenboom',\n",
       "  'subject',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'testicles',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'lambada',\n",
       "  'oit',\n",
       "  'unc',\n",
       "  'edu',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'north',\n",
       "  'carolina',\n",
       "  'extended',\n",
       "  'bulletin',\n",
       "  'board',\n",
       "  'service',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'lines',\n",
       "  'husband',\n",
       "  'woke',\n",
       "  'three',\n",
       "  'days',\n",
       "  'ago',\n",
       "  'small',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'spot',\n",
       "  'size',\n",
       "  'nickel',\n",
       "  'one',\n",
       "  'testicles',\n",
       "  'bottom',\n",
       "  'side',\n",
       "  'knots',\n",
       "  'lumps',\n",
       "  'little',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'says',\n",
       "  'reminds',\n",
       "  'bruise',\n",
       "  'feels',\n",
       "  'recollection',\n",
       "  'hitting',\n",
       "  'anything',\n",
       "  'like',\n",
       "  'would',\n",
       "  'cause',\n",
       "  'bruise',\n",
       "  'asssures',\n",
       "  'remember',\n",
       "  'something',\n",
       "  'like',\n",
       "  'clues',\n",
       "  'might',\n",
       "  'somewhat',\n",
       "  'hypochondriac',\n",
       "  'sp',\n",
       "  'sure',\n",
       "  'gonna',\n",
       "  'die',\n",
       "  'thanks',\n",
       "  'opinions',\n",
       "  'expressed',\n",
       "  'necessarily',\n",
       "  'university',\n",
       "  'north',\n",
       "  'carolina',\n",
       "  'chapel',\n",
       "  'hill',\n",
       "  'campus',\n",
       "  'office',\n",
       "  'information',\n",
       "  'technology',\n",
       "  'experimental',\n",
       "  'bulletin',\n",
       "  'board',\n",
       "  'service',\n",
       "  'internet',\n",
       "  'launchpad',\n",
       "  'unc',\n",
       "  'edu']]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmmnYr5uYl98",
    "outputId": "af5374f0-0795-44c4-cab6-824018945662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.69 s, sys: 15.4 ms, total: 6.7 s\n",
      "Wall time: 5.36 s\n"
     ]
    }
   ],
   "source": [
    "%time model_imdb = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NO6VUvn_YscM",
    "outputId": "7042afa7-1b3e-416a-bb2e-595a7f9698e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('voltage', 0.9868993759155273), ('want', 0.9866833686828613), ('used', 0.9850101470947266), ('using', 0.9848124980926514), ('amp', 0.9846521019935608)]\n"
     ]
    }
   ],
   "source": [
    "# Проверим, что модель обучилась\n",
    "print(model_imdb.wv.most_similar(positive=['find'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4X9PMpQUYsZk"
   },
   "outputs": [],
   "source": [
    "def sentiment_2(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbecfurNYykN"
   },
   "source": [
    "**Проверка качества работы модели word2vec**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaFfGYMCYl7N"
   },
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    '''\n",
    "    Для текста усредним вектора входящих в него слов\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean(\n",
    "            [self.model[w] for w in words if w in self.model] \n",
    "            or [np.zeros(self.size)], axis=0)\n",
    "            for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaqPJmLmY2bU"
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWj_WuOAY2Nt"
   },
   "outputs": [],
   "source": [
    "# Обучающая и тестовая выборки\n",
    "boundary = 1500\n",
    "X_train = corpus[:boundary] \n",
    "X_test = corpus[boundary:]\n",
    "y_train = newsgroups['target'][:boundary]\n",
    "y_test = newsgroups['target'][boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuqw4osSY2LF",
    "outputId": "f01f7cf7-3d5c-4d98-d6ab-ae511ddb8586"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.8157894736842105\n",
      "1 \t 0.9223300970873787\n",
      "2 \t 0.7660550458715596\n",
      "3 \t 0.7324561403508771\n"
     ]
    }
   ],
   "source": [
    "sentiment_2(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“Зо Хтет Аунг(ЛаБ-5)ММО”的副本",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
